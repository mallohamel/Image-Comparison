{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from inception_blocks import *\n",
    "K.set_image_data_format('channels_first')\n",
    "from fr_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss as defined by formula (3)\n",
    "    \n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor images, of shape (None, 128)\n",
    "            positive -- the encodings for the positive images, of shape (None, 128)\n",
    "            negative -- the encodings for the negative images, of shape (None, 128)\n",
    "    \n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    \n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    \n",
    "    ### START CODE HERE ### (Ëœ 4 lines)\n",
    "    # Step 1: Compute the (encoding) distance between the anchor and the positive, you will need to sum over axis=-1\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,positive)),axis=-1)\n",
    "    # Step 2: Compute the (encoding) distance between the anchor and the negative, you will need to sum over axis=-1\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,negative)),axis=-1)\n",
    "    # Step 3: subtract the two previous distances and add alpha.\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist,neg_dist),alpha)\n",
    "    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return loss\n",
    "\n",
    "FRmodel = faceRecoModel(input_shape=(3, 96, 96))\n",
    "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
    "load_weights_from_FaceNet(FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_images(image_path_original,image_path_check):\n",
    "    \n",
    "    imageA=mpimg.imread(image_path_original)\n",
    "    imageB=mpimg.imread(image_path_check)\n",
    "    fig = plt.figure(\"Comparison\")\n",
    " \n",
    "    # show first image\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    plt.imshow(imageA, cmap = plt.cm.gray)\n",
    "    plt.axis(\"off\")\n",
    " \n",
    "    # show the second image\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    plt.imshow(imageB, cmap = plt.cm.gray)\n",
    "    plt.axis(\"off\")\n",
    " \n",
    "    # show the images\n",
    "    plt.show()\n",
    "\n",
    "def verify(image_path_original, image_path_check, model): \n",
    "    \n",
    "    encoding_original = img_to_encoding(image_path_original,model)\n",
    "    encoding_check = img_to_encoding(image_path_check,model)\n",
    "  \n",
    "    dist = np.linalg.norm(encoding_original-encoding_check)\n",
    "    # setup the figure\n",
    "    \n",
    "    show_images(image_path_original,image_path_check)\n",
    "    \n",
    "    print (\"Distance is \" , dist)\n",
    "    if dist < 0.7:\n",
    "        print(\"It's similar\")\n",
    "                \n",
    "    else:\n",
    "        print(\"It's not similar\")\n",
    "    return dist\n",
    "\n",
    "def verify_ml_approach(image_path_original,image_path_check):\n",
    "\n",
    "    dist = verify(image_path_original, image_path_check, FRmodel)\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance is  0.62450016\n",
      "It's similar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.62450016"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify_ml_approach(\"images/image6.png\", \"images/image9.png\")\n",
    "#verify_ml_approach(\"images/Original.png\", \"images/Negative.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
